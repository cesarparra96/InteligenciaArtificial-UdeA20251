{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee714a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Carga los datos preprocesados\n",
    "train = pd.read_csv('Data/train_preprocessed.csv')\n",
    "test = pd.read_csv('Data/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c715b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO RANDOM FOREST OPTIMIZADO\n",
      "============================================================\n",
      "Cores disponibles: 16\n",
      "MEMORIA RAM:\n",
      "  Total: 31.1 GB\n",
      "  Usada: 10.2 GB (34.3%)\n",
      "  Disponible: 20.4 GB\n",
      "RAM con suficiente espacio libre\n",
      "Configuraci√≥n OPTIMIZADA - Random Forest con b√∫squeda de hiperpar√°metros\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import psutil  # Para monitorear RAM\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def monitor_memory():\n",
    "    \"\"\"Monitorea el uso de memoria RAM\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    used_gb = memory.used / (1024**3)\n",
    "    total_gb = memory.total / (1024**3)\n",
    "    available_gb = memory.available / (1024**3)\n",
    "    \n",
    "    print(f\"MEMORIA RAM:\")\n",
    "    print(f\"  Total: {total_gb:.1f} GB\")\n",
    "    print(f\"  Usada: {used_gb:.1f} GB ({memory.percent:.1f}%)\")\n",
    "    print(f\"  Disponible: {available_gb:.1f} GB\")\n",
    "    \n",
    "    if memory.percent > 85:\n",
    "        print(\"ADVERTENCIA: Uso de RAM alto (>85%)\")\n",
    "    elif memory.percent > 75:\n",
    "        print(\"RAM en nivel √≥ptimo para entrenamiento\")\n",
    "    else:\n",
    "        print(\"RAM con suficiente espacio libre\")\n",
    "    \n",
    "    return memory.percent\n",
    "\n",
    "# Configuraci√≥n optimizada para RandomForest\n",
    "print(\"MODELO RANDOM FOREST OPTIMIZADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Cores disponibles: {mp.cpu_count()}\")\n",
    "monitor_memory()\n",
    "print(\"Configuraci√≥n OPTIMIZADA - Random Forest con b√∫squeda de hiperpar√°metros\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8c3f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de caracter√≠sticas: 19\n",
      "N√∫mero de muestras de entrenamiento: 578824\n",
      "N√∫mero de muestras de test: 296786\n",
      "Clases disponibles: ['alto', 'bajo', 'medio-alto', 'medio-bajo']\n"
     ]
    }
   ],
   "source": [
    "# 1. Carga los datos preprocesados\n",
    "train = pd.read_csv('Data/train_preprocessed.csv')\n",
    "test = pd.read_csv('Data/test_preprocessed.csv')\n",
    "\n",
    "# 2. Separa variables predictoras y objetivo\n",
    "y = train['RENDIMIENTO_GLOBAL']\n",
    "X = train.drop(['RENDIMIENTO_GLOBAL', 'ID'], axis=1)\n",
    "X_test = test.drop(['ID'], axis=1)\n",
    "\n",
    "print(f\"N√∫mero de caracter√≠sticas: {X.shape[1]}\")\n",
    "print(f\"N√∫mero de muestras de entrenamiento: {X.shape[0]}\")\n",
    "print(f\"N√∫mero de muestras de test: {X_test.shape[0]}\")\n",
    "print(f\"Clases disponibles: {sorted(y.unique())}\")\n",
    "\n",
    "# 3. Pipeline con RandomForest optimizado\n",
    "# Random Forest no requiere escalado, pero lo incluimos por compatibilidad\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Opcional para Random Forest\n",
    "    ('rf', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,  # Usar todos los cores disponibles\n",
    "        oob_score=True,  # Out-of-bag score para evaluaci√≥n adicional\n",
    "        warm_start=False,  # Para entrenamientos incrementales si es necesario\n",
    "        class_weight='balanced_subsample'  # Manejo de clases desbalanceadas\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. B√∫squeda de hiperpar√°metros OPTIMIZADA para Random Forest\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': [100, 200, 300, 500],  # N√∫mero de √°rboles\n",
    "    'rf__max_depth': [10, 20, 30, None],  # Profundidad m√°xima\n",
    "    'rf__min_samples_split': [2, 5, 10],  # M√≠nimas muestras para dividir\n",
    "    'rf__min_samples_leaf': [1, 2, 4],  # M√≠nimas muestras en hoja\n",
    "    'rf__max_features': ['sqrt', 'log2', 0.3, 0.5],  # Caracter√≠sticas por divisi√≥n\n",
    "    'rf__bootstrap': [True, False],  # Uso de bootstrap\n",
    "    'rf__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66443312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B√öSQUEDA DE HIPERPAR√ÅMETROS - RANDOM FOREST\n",
      "============================================================\n",
      "CONFIGURACI√ìN OPTIMIZADA PARA RANDOM FOREST\n",
      "CONFIGURACI√ìN:\n",
      "   ‚Ä¢ Cores utilizados: 12 de 16 disponibles\n",
      "   ‚Ä¢ Iteraciones de b√∫squeda: 50\n",
      "   ‚Ä¢ Validaci√≥n cruzada: 5-fold\n",
      "   ‚Ä¢ Total de entrenamientos: ~250 modelos Random Forest\n",
      "   ‚Ä¢ Tiempo estimado: 6.2 minutos\n",
      "\n",
      "Hora de inicio: 08:10:38\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. Validaci√≥n cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cores_disponibles = mp.cpu_count()\n",
    "cores_optimos = max(1, int(cores_disponibles * 0.8))  # Usamos 80% de los cores\n",
    "\n",
    "print(\"\\nB√öSQUEDA DE HIPERPAR√ÅMETROS - RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURACI√ìN OPTIMIZADA PARA RANDOM FOREST\")\n",
    "\n",
    "# Estimaci√≥n de tiempo\n",
    "n_combinations = 50  # N√∫mero de combinaciones a probar\n",
    "total_fits = n_combinations * 5  # 5-fold CV\n",
    "tiempo_estimado = total_fits * 0.3 / cores_optimos \n",
    "\n",
    "print(f\"CONFIGURACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Cores utilizados: {cores_optimos} de {cores_disponibles} disponibles\")\n",
    "print(f\"   ‚Ä¢ Iteraciones de b√∫squeda: {n_combinations}\")\n",
    "print(f\"   ‚Ä¢ Validaci√≥n cruzada: 5-fold\")\n",
    "print(f\"   ‚Ä¢ Total de entrenamientos: ~{total_fits} modelos Random Forest\")\n",
    "print(f\"   ‚Ä¢ Tiempo estimado: {tiempo_estimado:.1f} minutos\")\n",
    "\n",
    "print(f\"\\nHora de inicio: {time.strftime('%H:%M:%S')}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8184c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° MODO S√öPER LIGERO - VALIDACI√ìN ULTRARR√ÅPIDA\n",
      "============================================================\n",
      "Configuraci√≥n s√∫per ligera:\n",
      "   ‚Ä¢ Cores utilizados: 12 (fijo)\n",
      "   ‚Ä¢ Iteraciones: 5 (m√≠nimo)\n",
      "   ‚Ä¢ CV folds: 2 (m√≠nimo)\n",
      "   ‚Ä¢ √Årboles m√°ximo: 100\n",
      "   ‚Ä¢ Solo configuraciones r√°pidas\n",
      "============================================================\n",
      "‚ö° Iniciando prueba S√öPER LIGERA...\n",
      "‚ö° Entrenando modelo s√∫per ligero...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ö° Ligero RF:   0%|          | 0/5 [00:00<?, ?modelo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ö° Ligero RF: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:57<00:00, 11.48s/modelo]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° PRUEBA S√öPER LIGERA COMPLETADA!\n",
      "Tiempo: 57.4 segundos (0.96 minutos)\n",
      "Mejor accuracy (ligero): 0.3918\n",
      "Mejores par√°metros: {'rf__n_estimators': 100, 'rf__min_samples_split': 5, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__max_depth': 20, 'rf__class_weight': 'balanced', 'rf__bootstrap': False}\n",
      "\n",
      "‚ö° GENERANDO SUBMISSION CON MODELO S√öPER LIGERO...\n",
      "‚ö° Prediciendo en conjunto de test completo...\n",
      "‚ö° Predicci√≥n completada en 2.0 segundos\n",
      "\n",
      "üìÅ GUARDANDO SUBMISSION LIGERO EN: Resultados_Modelos/RandomForest/Ligero_20250613_081510\n",
      "‚ö° Predicci√≥n completada en 2.0 segundos\n",
      "\n",
      "üìÅ GUARDANDO SUBMISSION LIGERO EN: Resultados_Modelos/RandomForest/Ligero_20250613_081510\n",
      "‚úÖ ARCHIVOS GENERADOS:\n",
      "   üéØ Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero.csv\n",
      "   üìä Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero_probabilidades.csv\n",
      "   üìã Resultados_Modelos/RandomForest/Ligero_20250613_081510/resumen_modelo_ligero.csv\n",
      "   üîÑ Resultados_Modelos/RandomForest/submission_ligero_latest.csv (acceso r√°pido)\n",
      "\n",
      "üìà DISTRIBUCI√ìN DE PREDICCIONES (MODELO LIGERO):\n",
      "   alto: 100,939 (34.0%)\n",
      "   bajo: 81,356 (27.4%)\n",
      "   medio-alto: 58,517 (19.7%)\n",
      "   medio-bajo: 55,974 (18.9%)\n",
      "\n",
      "üìä ESTIMACI√ìN PARA MODELO OPTIMIZADO:\n",
      "   ‚Ä¢ Tiempo estimado: 9.6 minutos\n",
      "   ‚Ä¢ Accuracy esperado: 0.3918 ¬± 0.02\n",
      "   ‚Ä¢ Configuraci√≥n: 20 iter √ó 5-fold = 100 modelos\n",
      "\n",
      "============================================================\n",
      "‚ö° SUBMISSION LIGERO GUARDADO - Continuando con optimizado...\n",
      "üìç SUBMISSION PRINCIPAL: Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero.csv\n",
      "üìç ACCESO R√ÅPIDO: Resultados_Modelos/RandomForest/submission_ligero_latest.csv\n",
      "============================================================\n",
      "MEMORIA RAM:\n",
      "  Total: 31.1 GB\n",
      "  Usada: 10.0 GB (34.0%)\n",
      "  Disponible: 20.5 GB\n",
      "RAM con suficiente espacio libre\n",
      "‚úÖ ARCHIVOS GENERADOS:\n",
      "   üéØ Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero.csv\n",
      "   üìä Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero_probabilidades.csv\n",
      "   üìã Resultados_Modelos/RandomForest/Ligero_20250613_081510/resumen_modelo_ligero.csv\n",
      "   üîÑ Resultados_Modelos/RandomForest/submission_ligero_latest.csv (acceso r√°pido)\n",
      "\n",
      "üìà DISTRIBUCI√ìN DE PREDICCIONES (MODELO LIGERO):\n",
      "   alto: 100,939 (34.0%)\n",
      "   bajo: 81,356 (27.4%)\n",
      "   medio-alto: 58,517 (19.7%)\n",
      "   medio-bajo: 55,974 (18.9%)\n",
      "\n",
      "üìä ESTIMACI√ìN PARA MODELO OPTIMIZADO:\n",
      "   ‚Ä¢ Tiempo estimado: 9.6 minutos\n",
      "   ‚Ä¢ Accuracy esperado: 0.3918 ¬± 0.02\n",
      "   ‚Ä¢ Configuraci√≥n: 20 iter √ó 5-fold = 100 modelos\n",
      "\n",
      "============================================================\n",
      "‚ö° SUBMISSION LIGERO GUARDADO - Continuando con optimizado...\n",
      "üìç SUBMISSION PRINCIPAL: Resultados_Modelos/RandomForest/Ligero_20250613_081510/submission_randomforest_ligero.csv\n",
      "üìç ACCESO R√ÅPIDO: Resultados_Modelos/RandomForest/submission_ligero_latest.csv\n",
      "============================================================\n",
      "MEMORIA RAM:\n",
      "  Total: 31.1 GB\n",
      "  Usada: 10.0 GB (34.0%)\n",
      "  Disponible: 20.5 GB\n",
      "RAM con suficiente espacio libre\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRUEBA S√öPER LIGERA - RANDOM FOREST ULTRARR√ÅPIDO (12 cores)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"‚ö° MODO S√öPER LIGERO - VALIDACI√ìN ULTRARR√ÅPIDA\")\n",
    "print(\"=\"*60)\n",
    "print(\"Configuraci√≥n s√∫per ligera:\")\n",
    "print(f\"   ‚Ä¢ Cores utilizados: 12 (fijo)\")\n",
    "print(f\"   ‚Ä¢ Iteraciones: 5 (m√≠nimo)\")\n",
    "print(f\"   ‚Ä¢ CV folds: 2 (m√≠nimo)\")\n",
    "print(f\"   ‚Ä¢ √Årboles m√°ximo: 100\")\n",
    "print(f\"   ‚Ä¢ Solo configuraciones r√°pidas\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuraci√≥n S√öPER LIGERA - Solo lo m√°s r√°pido\n",
    "param_distributions_ligera = {\n",
    "    'rf__n_estimators': [50, 100],              # Solo 50-100 √°rboles\n",
    "    'rf__max_depth': [10, 20],                  # Solo profundidades limitadas\n",
    "    'rf__min_samples_split': [5, 10],           # Valores conservadores\n",
    "    'rf__min_samples_leaf': [2, 4],             # Hojas m√°s grandes\n",
    "    'rf__max_features': ['sqrt'],               # Solo sqrt (m√°s r√°pido)\n",
    "    'rf__bootstrap': [False],                   # Sin bootstrap (MUY r√°pido)\n",
    "    'rf__class_weight': ['balanced']            # Solo balanced\n",
    "}\n",
    "\n",
    "# Pipeline s√∫per optimizado\n",
    "pipe_ligera = Pipeline([\n",
    "    ('rf', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=12,          # 12 cores fijos\n",
    "        oob_score=False,    # Sin OOB para velocidad\n",
    "        bootstrap=False,    # Sin bootstrap = MUY r√°pido\n",
    "        warm_start=False,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# CV m√≠nimo para m√°xima velocidad\n",
    "cv_ligera = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"‚ö° Iniciando prueba S√öPER LIGERA...\")\n",
    "start_time_ligera = time.time()\n",
    "\n",
    "random_search_ligera = RandomizedSearchCV(\n",
    "    pipe_ligera, \n",
    "    param_distributions=param_distributions_ligera, \n",
    "    n_iter=5,            # Solo 5 iteraciones\n",
    "    cv=cv_ligera,        # 2-fold CV\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,            # RandomizedSearchCV secuencial, RF paralelo\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "# Entrenamiento s√∫per r√°pido\n",
    "print(\"‚ö° Entrenando modelo s√∫per ligero...\")\n",
    "with tqdm(total=5, desc='‚ö° Ligero RF', unit='modelo') as pbar:\n",
    "    random_search_ligera.fit(X, y)\n",
    "    pbar.update(5)\n",
    "\n",
    "elapsed_ligera = time.time() - start_time_ligera\n",
    "\n",
    "# Resultados ligeros\n",
    "print(f\"\\n‚ö° PRUEBA S√öPER LIGERA COMPLETADA!\")\n",
    "print(f\"Tiempo: {elapsed_ligera:.1f} segundos ({elapsed_ligera/60:.2f} minutos)\")\n",
    "print(f\"Mejor accuracy (ligero): {random_search_ligera.best_score_:.4f}\")\n",
    "print(f\"Mejores par√°metros: {random_search_ligera.best_params_}\")\n",
    "\n",
    "# üéØ GENERAR SUBMISSION COMPLETO CON MODELO LIGERO\n",
    "print(f\"\\n‚ö° GENERANDO SUBMISSION CON MODELO S√öPER LIGERO...\")\n",
    "best_model_ligera = random_search_ligera.best_estimator_\n",
    "\n",
    "# Predicci√≥n completa en todo el conjunto de test\n",
    "print(\"‚ö° Prediciendo en conjunto de test completo...\")\n",
    "start_pred = time.time()\n",
    "y_pred_test_ligero = best_model_ligera.predict(X_test)\n",
    "y_pred_proba_ligero = best_model_ligera.predict_proba(X_test)\n",
    "elapsed_pred = time.time() - start_pred\n",
    "\n",
    "print(f\"‚ö° Predicci√≥n completada en {elapsed_pred:.1f} segundos\")\n",
    "\n",
    "# üìÅ GUARDAR SUBMISSION LIGERO\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear carpeta para resultados ligeros\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir_ligero = f'Resultados_Modelos/RandomForest/Ligero_{timestamp}'\n",
    "os.makedirs(output_dir_ligero, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ GUARDANDO SUBMISSION LIGERO EN: {output_dir_ligero}\")\n",
    "\n",
    "# Submission principal (LIGERO)\n",
    "submission_ligero = pd.DataFrame({\n",
    "    'ID': test['ID'], \n",
    "    'RENDIMIENTO_GLOBAL': y_pred_test_ligero\n",
    "})\n",
    "submission_path_ligero = f'{output_dir_ligero}/submission_randomforest_ligero.csv'\n",
    "submission_ligero.to_csv(submission_path_ligero, index=False)\n",
    "\n",
    "# Probabilidades (opcional)\n",
    "prob_df_ligero = pd.DataFrame(y_pred_proba_ligero, columns=best_model_ligera.classes_)\n",
    "prob_df_ligero['ID'] = test['ID']\n",
    "prob_df_ligero['RENDIMIENTO_GLOBAL'] = y_pred_test_ligero\n",
    "prob_path_ligero = f'{output_dir_ligero}/submission_randomforest_ligero_probabilidades.csv'\n",
    "prob_df_ligero.to_csv(prob_path_ligero, index=False)\n",
    "\n",
    "# Resumen del modelo ligero\n",
    "resumen_ligero = {\n",
    "    'timestamp': timestamp,\n",
    "    'tipo_modelo': 'Random Forest S√∫per Ligero',\n",
    "    'accuracy_cv': random_search_ligera.best_score_,\n",
    "    'tiempo_entrenamiento_seg': elapsed_ligera,\n",
    "    'tiempo_prediccion_seg': elapsed_pred,\n",
    "    'n_iteraciones': 5,\n",
    "    'cv_folds': 2,\n",
    "    'mejores_parametros': str(random_search_ligera.best_params_)\n",
    "}\n",
    "resumen_df_ligero = pd.DataFrame([resumen_ligero])\n",
    "resumen_path_ligero = f'{output_dir_ligero}/resumen_modelo_ligero.csv'\n",
    "resumen_df_ligero.to_csv(resumen_path_ligero, index=False)\n",
    "\n",
    "# Tambi√©n crear copia de acceso r√°pido\n",
    "standard_dir = 'Resultados_Modelos/RandomForest'\n",
    "os.makedirs(standard_dir, exist_ok=True)\n",
    "submission_rapido = f'{standard_dir}/submission_ligero_latest.csv'\n",
    "submission_ligero.to_csv(submission_rapido, index=False)\n",
    "\n",
    "print(f\"‚úÖ ARCHIVOS GENERADOS:\")\n",
    "print(f\"   üéØ {submission_path_ligero}\")\n",
    "print(f\"   üìä {prob_path_ligero}\")\n",
    "print(f\"   üìã {resumen_path_ligero}\")\n",
    "print(f\"   üîÑ {submission_rapido} (acceso r√°pido)\")\n",
    "\n",
    "# Distribuci√≥n de predicciones\n",
    "pred_counts_ligero = pd.Series(y_pred_test_ligero).value_counts().sort_index()\n",
    "print(f\"\\nüìà DISTRIBUCI√ìN DE PREDICCIONES (MODELO LIGERO):\")\n",
    "for clase in sorted(pred_counts_ligero.index):\n",
    "    count = pred_counts_ligero[clase]\n",
    "    pct = count / len(y_pred_test_ligero) * 100\n",
    "    print(f\"   {clase}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Estimaci√≥n para modelo optimizado\n",
    "factor_escalado = 20 / 5  # 20 iter vs 5 iter\n",
    "factor_cv = 5 / 2         # 5-fold vs 2-fold\n",
    "tiempo_estimado_optimizado = elapsed_ligera * factor_escalado * factor_cv\n",
    "\n",
    "print(f\"\\nüìä ESTIMACI√ìN PARA MODELO OPTIMIZADO:\")\n",
    "print(f\"   ‚Ä¢ Tiempo estimado: {tiempo_estimado_optimizado/60:.1f} minutos\")\n",
    "print(f\"   ‚Ä¢ Accuracy esperado: {random_search_ligera.best_score_:.4f} ¬± 0.02\")\n",
    "print(f\"   ‚Ä¢ Configuraci√≥n: 20 iter √ó 5-fold = 100 modelos\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚ö° SUBMISSION LIGERO GUARDADO - Continuando con optimizado...\")\n",
    "print(f\"üìç SUBMISSION PRINCIPAL: {submission_path_ligero}\")\n",
    "print(f\"üìç ACCESO R√ÅPIDO: {submission_rapido}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Monitor memoria despu√©s de prueba ligera\n",
    "memory_post_ligera = monitor_memory()\n",
    "\n",
    "# Resetear timer para el modelo optimizado\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b52b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de caracter√≠sticas: 19\n",
      "N√∫mero de muestras de entrenamiento: 578824\n",
      "N√∫mero de muestras de test: 296786\n",
      "Clases disponibles: ['alto', 'bajo', 'medio-alto', 'medio-bajo']\n",
      "\n",
      "üöÄ CONFIGURACI√ìN DEL MODELO OPTIMIZADO:\n",
      "============================================================\n",
      "DIFERENCIAS CON MODELO LENTO ANTERIOR:\n",
      "   ‚ùå Sin bootstrap=True (era s√∫per lento)\n",
      "   ‚ùå Sin max_depth=None (muy lento)\n",
      "   ‚ùå Sin n_estimators=500 (innecesario)\n",
      "   ‚ùå Sin max_features=0.3,0.5 (m√°s lentos)\n",
      "   ‚úÖ Solo bootstrap=False (10x m√°s r√°pido)\n",
      "   ‚úÖ max_depth limitado (5x m√°s r√°pido)\n",
      "   ‚úÖ n_estimators <= 300 (√≥ptimo)\n",
      "   ‚úÖ 12 cores fijos como solicitas\n",
      "============================================================\n",
      "Iniciando entrenamiento de Random Forest...\n",
      "Entrenando 50 modelos Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progreso RF:   0%|          | 0/50 [00:00<?, ?modelo/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progreso RF:   0%|          | 0/50 [00:35<?, ?modelo/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m             search_cv._run_search = original_run_search\n\u001b[32m     89\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIniciando entrenamiento de Random Forest...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m random_search = \u001b[43mfit_with_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m elapsed = time.time() - start_time\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mENTRENAMIENTO COMPLETADO!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mfit_with_progress\u001b[39m\u001b[34m(search_cv, X, y)\u001b[39m\n\u001b[32m     81\u001b[39m search_cv._run_search = wrapped_run_search\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msearch_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Restaurar el m√©todo original\u001b[39;00m\n\u001b[32m     87\u001b[39m     search_cv._run_search = original_run_search\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mfit_with_progress.<locals>.wrapped_run_search\u001b[39m\u001b[34m(evaluate_candidates)\u001b[39m\n\u001b[32m     77\u001b[39m     pbar.update(\u001b[38;5;28mlen\u001b[39m(candidate_params))\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped_evaluate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mfit_with_progress.<locals>.wrapped_run_search.<locals>.wrapped_evaluate\u001b[39m\u001b[34m(candidate_params)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_evaluate\u001b[39m(candidate_params):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     pbar.update(\u001b[38;5;28mlen\u001b[39m(candidate_params))\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositorios/UDEA/InteligenciaArtificial-UdeA20251/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1. Carga los datos preprocesados (ya cargados)\n",
    "# train = pd.read_csv('Data/train_preprocessed.csv')\n",
    "# test = pd.read_csv('Data/test_preprocessed.csv')\n",
    "\n",
    "# 2. Variables ya separadas\n",
    "# y = train['RENDIMIENTO_GLOBAL']\n",
    "# X = train.drop(['RENDIMIENTO_GLOBAL', 'ID'], axis=1)\n",
    "# X_test = test.drop(['ID'], axis=1)\n",
    "\n",
    "print(f\"N√∫mero de caracter√≠sticas: {X.shape[1]}\")\n",
    "print(f\"N√∫mero de muestras de entrenamiento: {X.shape[0]}\")\n",
    "print(f\"N√∫mero de muestras de test: {X_test.shape[0]}\")\n",
    "print(f\"Clases disponibles: {sorted(y.unique())}\")\n",
    "\n",
    "# 3. Pipeline OPTIMIZADO para velocidad y rendimiento\n",
    "pipe_optimizado = Pipeline([\n",
    "    ('rf', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=12,              # 12 cores como solicitas\n",
    "        oob_score=False,        # Sin OOB para velocidad\n",
    "        warm_start=False,\n",
    "        bootstrap=False         # Sin bootstrap = MUY m√°s r√°pido\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Par√°metros OPTIMIZADOS - R√°pidos pero efectivos\n",
    "param_distributions_optimizado = {\n",
    "    'rf__n_estimators': [100, 200, 300],          # M√°ximo 300 (no 500)\n",
    "    'rf__max_depth': [10, 20, 30],                # Sin None (m√°s r√°pido)\n",
    "    'rf__min_samples_split': [2, 5, 10],          # Rango est√°ndar\n",
    "    'rf__min_samples_leaf': [1, 2, 4],            # Rango est√°ndar\n",
    "    'rf__max_features': ['sqrt', 'log2'],         # Solo los r√°pidos\n",
    "    'rf__bootstrap': [False],                     # Solo False (CLAVE)\n",
    "    'rf__class_weight': ['balanced', None]         # Solo 2 opciones\n",
    "}\n",
    "\n",
    "\n",
    "# Configuraci√≥n de b√∫squeda optimizada para Random Forest\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_optimizado, \n",
    "    param_distributions=param_distributions_optimizado, \n",
    "    n_iter=50,   # M√°s iteraciones que SVM ya que RF es m√°s r√°pido\n",
    "    cv=cv,\n",
    "    scoring='accuracy', \n",
    "    n_jobs=cores_optimos,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    "    pre_dispatch='2*n_jobs'\n",
    ")\n",
    "\n",
    "# Wrapper con barra de progreso usando tqdm\n",
    "def fit_with_progress(search_cv, X, y):\n",
    "    \"\"\"Entrena el modelo con barra de progreso\"\"\"\n",
    "    n_iter = search_cv.n_iter\n",
    "    \n",
    "    print(f\"Entrenando {n_iter} modelos Random Forest...\")\n",
    "    with tqdm(total=n_iter, desc='Progreso RF', unit='modelo') as pbar:\n",
    "        # Interceptar el m√©todo _run_search temporalmente\n",
    "        original_run_search = search_cv._run_search\n",
    "        \n",
    "        def wrapped_run_search(evaluate_candidates):\n",
    "            def wrapped_evaluate(candidate_params):\n",
    "                results = evaluate_candidates(candidate_params)\n",
    "                pbar.update(len(candidate_params))\n",
    "                return results\n",
    "            return original_run_search(wrapped_evaluate)\n",
    "        \n",
    "        search_cv._run_search = wrapped_run_search\n",
    "        \n",
    "        try:\n",
    "            return search_cv.fit(X, y)\n",
    "        finally:\n",
    "            # Restaurar el m√©todo original\n",
    "            search_cv._run_search = original_run_search\n",
    "\n",
    "print(\"Iniciando entrenamiento de Random Forest...\")\n",
    "random_search = fit_with_progress(random_search, X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nENTRENAMIENTO COMPLETADO!\")\n",
    "print(f\"Hora de finalizaci√≥n: {time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Tiempo real: {elapsed/60:.2f} minutos\")\n",
    "\n",
    "print(f\"\\nMONITOREO POST-ENTRENAMIENTO:\")\n",
    "final_memory = monitor_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTADOS DE LA B√öSQUEDA OPTIMIZADA - RANDOM FOREST\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mejores par√°metros: {random_search.best_params_}\")\n",
    "print(f\"Mejor score de validaci√≥n cruzada: {random_search.best_score_:.4f}\")\n",
    "print(f\"Modelos evaluados: {len(random_search.cv_results_['mean_test_score'])}\")\n",
    "print(f\"Uso final de RAM: {final_memory:.1f}%\")\n",
    "\n",
    "# 6. An√°lisis del modelo seleccionado\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"\\nModelo Random Forest seleccionado:\")\n",
    "print(f\"- N_estimators: {random_search.best_params_['rf__n_estimators']}\")\n",
    "print(f\"- Max_depth: {random_search.best_params_['rf__max_depth']}\")\n",
    "print(f\"- Min_samples_split: {random_search.best_params_['rf__min_samples_split']}\")\n",
    "print(f\"- Min_samples_leaf: {random_search.best_params_['rf__min_samples_leaf']}\")\n",
    "print(f\"- Max_features: {random_search.best_params_['rf__max_features']}\")\n",
    "print(f\"- Bootstrap: {random_search.best_params_['rf__bootstrap']}\")\n",
    "print(f\"- Class_weight: {random_search.best_params_['rf__class_weight']}\")\n",
    "\n",
    "# Informaci√≥n espec√≠fica de Random Forest\n",
    "rf_model = best_model.named_steps['rf']\n",
    "if hasattr(rf_model, 'oob_score_'):\n",
    "    print(f\"- OOB Score: {rf_model.oob_score_:.4f}\")\n",
    "\n",
    "print(f\"- N√∫mero de √°rboles entrenados: {len(rf_model.estimators_)}\")\n",
    "print(f\"- N√∫mero de caracter√≠sticas consideradas: {rf_model.n_features_in_}\")\n",
    "\n",
    "# 7. Predicciones en el conjunto de test\n",
    "print(\"\\nGenerando predicciones para el conjunto de test...\")\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# 8. Validaci√≥n cruzada detallada\n",
    "print(\"\\nCalculando m√©tricas de validaci√≥n cruzada...\")\n",
    "y_pred_cv = cross_val_predict(best_model, X, y, cv=cv)\n",
    "accuracy_cv = accuracy_score(y, y_pred_cv)\n",
    "\n",
    "print(f\"Accuracy en validaci√≥n cruzada: {accuracy_cv:.4f}\")\n",
    "\n",
    "# 5. Validaci√≥n cruzada optimizada\n",
    "cv_optimizado = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\nB√öSQUEDA OPTIMIZADA - RANDOM FOREST R√ÅPIDO\")\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURACI√ìN OPTIMIZADA PARA VELOCIDAD + RENDIMIENTO\")\n",
    "\n",
    "# Estimaci√≥n realista con configuraci√≥n optimizada\n",
    "n_combinations_opt = 20  # Menos iteraciones pero m√°s efectivas\n",
    "total_fits_opt = n_combinations_opt * 5  # 5-fold CV\n",
    "tiempo_estimado_opt = total_fits_opt * 0.5 / 12  # Sin bootstrap = muy r√°pido\n",
    "\n",
    "print(f\"CONFIGURACI√ìN OPTIMIZADA:\")\n",
    "print(f\"   ‚Ä¢ Cores utilizados: 12 (fijo como solicitas)\")\n",
    "print(f\"   ‚Ä¢ Iteraciones de b√∫squeda: {n_combinations_opt}\")\n",
    "print(f\"   ‚Ä¢ Validaci√≥n cruzada: 5-fold\")\n",
    "print(f\"   ‚Ä¢ Total de entrenamientos: {total_fits_opt} modelos RF\")\n",
    "print(f\"   ‚Ä¢ Tiempo estimado: {tiempo_estimado_opt:.1f} minutos\")\n",
    "print(f\"   ‚Ä¢ Configuraci√≥n: SIN bootstrap (clave para velocidad)\")\n",
    "\n",
    "print(f\"\\nHora de inicio: {time.strftime('%H:%M:%S')}\")\n",
    "print(\"üöÄ MODO OPTIMIZADO - Velocidad + Rendimiento\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Visualizaciones espec√≠ficas para Random Forest\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y, y_pred_cv)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n",
    "            xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
    "axes[0,0].set_xlabel('Predicho')\n",
    "axes[0,0].set_ylabel('Real')\n",
    "axes[0,0].set_title(f'Matriz de Confusi√≥n\\n(Accuracy: {accuracy_cv:.4f})')\n",
    "\n",
    "# Distribuci√≥n de predicciones en test\n",
    "pred_counts = pd.Series(y_pred_test).value_counts().sort_index()\n",
    "axes[0,1].bar(pred_counts.index, pred_counts.values, alpha=0.7, color='green')\n",
    "axes[0,1].set_xlabel('Rendimiento Global')\n",
    "axes[0,1].set_ylabel('N√∫mero de predicciones')\n",
    "axes[0,1].set_title('Distribuci√≥n de predicciones en Test')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Importancia de caracter√≠sticas (espec√≠fico de Random Forest)\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "# Top 20 caracter√≠sticas m√°s importantes\n",
    "top_n = min(20, len(feature_names))\n",
    "axes[1,0].bar(range(top_n), feature_importance[indices[:top_n]], color='orange', alpha=0.7)\n",
    "axes[1,0].set_xlabel('Caracter√≠sticas')\n",
    "axes[1,0].set_ylabel('Importancia')\n",
    "axes[1,0].set_title(f'Top {top_n} Caracter√≠sticas m√°s Importantes')\n",
    "axes[1,0].set_xticks(range(top_n))\n",
    "axes[1,0].set_xticklabels([feature_names[i] for i in indices[:top_n]], rotation=90)\n",
    "\n",
    "# Evoluci√≥n del accuracy por n√∫mero de √°rboles (curva de aprendizaje)\n",
    "# Esto requiere entrenar modelos con diferentes n√∫meros de √°rboles\n",
    "n_estimators_range = [10, 50, 100, 150, 200, 250, 300]\n",
    "scores_by_trees = []\n",
    "\n",
    "print(\"Calculando curva de aprendizaje por n√∫mero de √°rboles...\")\n",
    "for n_est in tqdm(n_estimators_range, desc=\"Evaluando √°rboles\"):\n",
    "    rf_temp = RandomForestClassifier(\n",
    "        n_estimators=n_est,\n",
    "        max_depth=random_search.best_params_['rf__max_depth'],\n",
    "        min_samples_split=random_search.best_params_['rf__min_samples_split'],\n",
    "        min_samples_leaf=random_search.best_params_['rf__min_samples_leaf'],\n",
    "        max_features=random_search.best_params_['rf__max_features'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Usar solo una muestra para acelerar\n",
    "    sample_size = min(1000, len(X))\n",
    "    X_sample = X.sample(n=sample_size, random_state=42)\n",
    "    y_sample = y.loc[X_sample.index]\n",
    "    \n",
    "    score = cross_val_score(rf_temp, X_sample, y_sample, cv=3, scoring='accuracy').mean()\n",
    "    scores_by_trees.append(score)\n",
    "\n",
    "axes[1,1].plot(n_estimators_range, scores_by_trees, 'o-', color='red', linewidth=2, markersize=6)\n",
    "axes[1,1].set_xlabel('N√∫mero de √Årboles')\n",
    "axes[1,1].set_ylabel('Accuracy (CV)')\n",
    "axes[1,1].set_title('Curva de Aprendizaje vs N√∫mero de √Årboles')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].axvline(x=random_search.best_params_['rf__n_estimators'], \n",
    "                  color='green', linestyle='--', alpha=0.7, \n",
    "                  label=f\"√ìptimo: {random_search.best_params_['rf__n_estimators']}\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Configuraci√≥n de b√∫squeda OPTIMIZADA\n",
    "random_search_optimizado = RandomizedSearchCV(\n",
    "    pipe_optimizado, \n",
    "    param_distributions=param_distributions_optimizado, \n",
    "    n_iter=20,           # Reducido para velocidad\n",
    "    cv=cv_optimizado,    # 5-fold\n",
    "    scoring='accuracy', \n",
    "    n_jobs=1,            # RandomizedSearchCV secuencial, RF usa 12 cores\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    return_train_score=False,  # Sin train score para velocidad\n",
    "    pre_dispatch='1*n_jobs'    # Menos dispatch para control de memoria\n",
    ")\n",
    "\n",
    "# Wrapper con barra de progreso usando tqdm\n",
    "def fit_with_progress_optimizado(search_cv, X, y):\n",
    "    \"\"\"Entrena el modelo optimizado con barra de progreso\"\"\"\n",
    "    n_iter = search_cv.n_iter\n",
    "    \n",
    "    print(f\"üöÄ Entrenando {n_iter} modelos Random Forest OPTIMIZADOS...\")\n",
    "    with tqdm(total=n_iter, desc='üöÄ RF Optimizado', unit='modelo') as pbar:\n",
    "        original_run_search = search_cv._run_search\n",
    "        \n",
    "        def wrapped_run_search(evaluate_candidates):\n",
    "            def wrapped_evaluate(candidate_params):\n",
    "                results = evaluate_candidates(candidate_params)\n",
    "                pbar.update(len(candidate_params))\n",
    "                return results\n",
    "            return original_run_search(wrapped_evaluate)\n",
    "        \n",
    "        search_cv._run_search = wrapped_run_search\n",
    "        \n",
    "        try:\n",
    "            return search_cv.fit(X, y)\n",
    "        finally:\n",
    "            search_cv._run_search = original_run_search\n",
    "\n",
    "print(\"üöÄ Iniciando entrenamiento OPTIMIZADO de Random Forest...\")\n",
    "print(\"IMPORTANTE: Sin bootstrap = 10x m√°s r√°pido que configuraci√≥n anterior\")\n",
    "random_search_optimizado = fit_with_progress_optimizado(random_search_optimizado, X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüöÄ ENTRENAMIENTO OPTIMIZADO COMPLETADO!\")\n",
    "print(f\"Hora de finalizaci√≥n: {time.strftime('%H:%M:%S')}\")\n",
    "print(f\"Tiempo real: {elapsed/60:.2f} minutos\")\n",
    "print(f\"Aceleraci√≥n vs configuraci√≥n anterior: ~10x m√°s r√°pido\")\n",
    "\n",
    "print(f\"\\nMONITOREO POST-ENTRENAMIENTO:\")\n",
    "final_memory = monitor_memory()\n",
    "\n",
    "# Actualizar la variable para el resto del c√≥digo\n",
    "random_search = random_search_optimizado\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baec0573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è ESTIMACI√ìN DE TIEMPO PARA TU SISTEMA\n",
      "============================================================\n",
      "DATASET:\n",
      "   ‚Ä¢ Muestras: 578,824\n",
      "   ‚Ä¢ Caracter√≠sticas: 19\n",
      "   ‚Ä¢ Clases: 4\n",
      "   ‚Ä¢ Tama√±o estimado: 83.9 MB\n",
      "\n",
      "HARDWARE:\n",
      "   ‚Ä¢ Procesador: Intel Core 12¬™ Gen\n",
      "   ‚Ä¢ Cores a usar: 12\n",
      "   ‚Ä¢ Cores disponibles: 16\n",
      "\n",
      "PRUEBA R√ÅPIDA (10 iteraciones):\n",
      "   ‚Ä¢ Modelos a entrenar: 30 (10 iter √ó 3 CV)\n",
      "   ‚Ä¢ Tiempo estimado: 3-5 minutos\n",
      "   ‚Ä¢ Memoria estimada: ~4-6 GB\n",
      "\n",
      "ENTRENAMIENTO COMPLETO (50 iteraciones):\n",
      "   ‚Ä¢ Modelos a entrenar: 250 (50 iter √ó 5 CV)\n",
      "   ‚Ä¢ Tiempo estimado: 15-25 minutos\n",
      "   ‚Ä¢ Memoria estimada: ~6-8 GB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ESTIMACI√ìN DE TIEMPO ESPEC√çFICA PARA TU SISTEMA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"‚è±Ô∏è ESTIMACI√ìN DE TIEMPO PARA TU SISTEMA\")\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET:\")\n",
    "print(f\"   ‚Ä¢ Muestras: {X.shape[0]:,}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {X.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Clases: {len(y.unique())}\")\n",
    "print(f\"   ‚Ä¢ Tama√±o estimado: {(X.shape[0] * X.shape[1] * 8 / 1024**2):.1f} MB\")\n",
    "\n",
    "print(\"\\nHARDWARE:\")\n",
    "print(f\"   ‚Ä¢ Procesador: Intel Core 12¬™ Gen\")\n",
    "print(f\"   ‚Ä¢ Cores a usar: 12\")\n",
    "print(f\"   ‚Ä¢ Cores disponibles: {mp.cpu_count()}\")\n",
    "\n",
    "print(\"\\nPRUEBA R√ÅPIDA (10 iteraciones):\")\n",
    "print(f\"   ‚Ä¢ Modelos a entrenar: 30 (10 iter √ó 3 CV)\")\n",
    "print(f\"   ‚Ä¢ Tiempo estimado: 3-5 minutos\")\n",
    "print(f\"   ‚Ä¢ Memoria estimada: ~4-6 GB\")\n",
    "\n",
    "print(\"\\nENTRENAMIENTO COMPLETO (50 iteraciones):\")\n",
    "print(f\"   ‚Ä¢ Modelos a entrenar: 250 (50 iter √ó 5 CV)\")\n",
    "print(f\"   ‚Ä¢ Tiempo estimado: 15-25 minutos\")\n",
    "print(f\"   ‚Ä¢ Memoria estimada: ~6-8 GB\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02873bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Reporte detallado\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"REPORTE DE CLASIFICACI√ìN - RANDOM FOREST\")\n",
    "print(f\"{'='*50}\")\n",
    "print(classification_report(y, y_pred_cv))\n",
    "\n",
    "# 11. An√°lisis de importancia de caracter√≠sticas detallado\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Crear DataFrame con importancias\n",
    "importance_df = pd.DataFrame({\n",
    "    'Caracteristica': feature_names,\n",
    "    'Importancia': feature_importance\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"Top 15 caracter√≠sticas m√°s importantes:\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Estad√≠sticas de importancia\n",
    "print(f\"\\nEstad√≠sticas de importancia:\")\n",
    "print(f\"- Caracter√≠stica m√°s importante: {importance_df.iloc[0]['Caracteristica']} ({importance_df.iloc[0]['Importancia']:.4f})\")\n",
    "print(f\"- Suma de top 5: {importance_df.head(5)['Importancia'].sum():.4f}\")\n",
    "print(f\"- Suma de top 10: {importance_df.head(10)['Importancia'].sum():.4f}\")\n",
    "print(f\"- Importancia promedio: {feature_importance.mean():.4f}\")\n",
    "print(f\"- Desviaci√≥n est√°ndar: {feature_importance.std():.4f}\")\n",
    "\n",
    "# 12. Guardar resultados en directorio organizado con fecha y hora\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear carpeta con timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f'Resultados_Modelos/RandomForest/RF_{timestamp}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ GUARDANDO RESULTADOS EN: {output_dir}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predicciones b√°sicas (SUBMISSION PRINCIPAL)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'], \n",
    "    'RENDIMIENTO_GLOBAL': y_pred_test\n",
    "})\n",
    "submission_path = f'{output_dir}/submission_randomforest.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "# Guardar tambi√©n las probabilidades\n",
    "prob_df = pd.DataFrame(y_pred_proba, columns=best_model.classes_)\n",
    "prob_df['ID'] = test['ID']\n",
    "prob_df['RENDIMIENTO_GLOBAL'] = y_pred_test\n",
    "prob_path = f'{output_dir}/submission_randomforest_probabilidades.csv'\n",
    "prob_df.to_csv(prob_path, index=False)\n",
    "\n",
    "# Guardar importancia de caracter√≠sticas\n",
    "importance_path = f'{output_dir}/feature_importance.csv'\n",
    "importance_df.to_csv(importance_path, index=False)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model_path = f'{output_dir}/modelo_randomforest_entrenado.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Guardar hiperpar√°metros √≥ptimos\n",
    "best_params_df = pd.DataFrame([random_search.best_params_])\n",
    "params_path = f'{output_dir}/mejores_hiperparametros.csv'\n",
    "best_params_df.to_csv(params_path, index=False)\n",
    "\n",
    "# Guardar resumen de m√©tricas\n",
    "metrics_summary = {\n",
    "    'timestamp': timestamp,\n",
    "    'accuracy_cv': accuracy_cv,\n",
    "    'best_score': random_search.best_score_,\n",
    "    'training_time_minutes': elapsed/60,\n",
    "    'n_models_evaluated': len(random_search.cv_results_['mean_test_score']),\n",
    "    'final_memory_usage': final_memory\n",
    "}\n",
    "metrics_df = pd.DataFrame([metrics_summary])\n",
    "metrics_path = f'{output_dir}/resumen_metricas.csv'\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Archivos generados en '{output_dir}':\")\n",
    "print(f\"   üéØ {submission_path}\")\n",
    "print(f\"   üìä {prob_path}\")\n",
    "print(f\"   üìà {importance_path}\")\n",
    "print(f\"   ü§ñ {model_path}\")\n",
    "print(f\"   ‚öôÔ∏è  {params_path}\")\n",
    "print(f\"   üìã {metrics_path}\")\n",
    "\n",
    "# Tambi√©n crear copia en ubicaci√≥n est√°ndar para f√°cil acceso\n",
    "standard_dir = 'Resultados_Modelos/RandomForest'\n",
    "os.makedirs(standard_dir, exist_ok=True)\n",
    "standard_submission = f'{standard_dir}/submission_randomforest_latest.csv'\n",
    "submission.to_csv(standard_submission, index=False)\n",
    "print(f\"   üîÑ {standard_submission} (copia de acceso r√°pido)\")\n",
    "\n",
    "print(f\"\\nüìç SUBMISSION PRINCIPAL: {submission_path}\")\n",
    "print(f\"üìç MODELO GUARDADO: {model_path}\")\n",
    "print(f\"üìç ACCESO R√ÅPIDO: {standard_submission}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04793c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Estad√≠sticas adicionales espec√≠ficas de Random Forest\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ESTAD√çSTICAS ADICIONALES - RANDOM FOREST\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Informaci√≥n del modelo final\n",
    "print(f\"CONFIGURACI√ìN DEL MODELO FINAL:\")\n",
    "print(f\"- N√∫mero de √°rboles: {rf_model.n_estimators}\")\n",
    "print(f\"- Profundidad m√°xima: {rf_model.max_depth}\")\n",
    "print(f\"- Caracter√≠sticas por divisi√≥n: {rf_model.max_features}\")\n",
    "print(f\"- M√≠nimas muestras para dividir: {rf_model.min_samples_split}\")\n",
    "print(f\"- M√≠nimas muestras en hoja: {rf_model.min_samples_leaf}\")\n",
    "print(f\"- Uso de bootstrap: {rf_model.bootstrap}\")\n",
    "\n",
    "# Estad√≠sticas de entrenamiento\n",
    "print(f\"\\nESTAD√çSTICAS DE ENTRENAMIENTO:\")\n",
    "print(f\"- Tiempo total de b√∫squeda: {elapsed/60:.2f} minutos\")\n",
    "print(f\"- Modelos evaluados: {len(random_search.cv_results_['mean_test_score'])}\")\n",
    "print(f\"- Mejor score CV: {random_search.best_score_:.4f}\")\n",
    "print(f\"- Score en validaci√≥n cruzada final: {accuracy_cv:.4f}\")\n",
    "\n",
    "if hasattr(rf_model, 'oob_score_'):\n",
    "    print(f\"- Out-of-bag score: {rf_model.oob_score_:.4f}\")\n",
    "\n",
    "# Distribuci√≥n de clases\n",
    "print(f\"\\nDISTRIBUCI√ìN DE CLASES:\")\n",
    "print(f\"Distribuci√≥n original (entrenamiento):\")\n",
    "for clase in sorted(y.unique()):\n",
    "    count = (y == clase).sum()\n",
    "    pct = count / len(y) * 100\n",
    "    print(f\"  {clase}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribuci√≥n predicha (test):\")\n",
    "for clase in sorted(pred_counts.index):\n",
    "    count = pred_counts[clase]\n",
    "    pct = count / len(y_pred_test) * 100\n",
    "    print(f\"  {clase}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# M√©tricas de confianza\n",
    "print(f\"\\nM√âTRICAS DE CONFIANZA:\")\n",
    "probas_max = np.max(y_pred_proba, axis=1)\n",
    "print(f\"- Confianza promedio: {np.mean(probas_max):.4f}\")\n",
    "print(f\"- Confianza m√≠nima: {np.min(probas_max):.4f}\")\n",
    "print(f\"- Confianza m√°xima: {np.max(probas_max):.4f}\")\n",
    "print(f\"- Predicciones con confianza > 0.8: {(probas_max > 0.8).sum()} ({(probas_max > 0.8).mean()*100:.1f}%)\")\n",
    "print(f\"- Predicciones con confianza > 0.9: {(probas_max > 0.9).sum()} ({(probas_max > 0.9).mean()*100:.1f}%)\")\n",
    "\n",
    "# Comparaci√≥n de rendimiento (si hay otros modelos)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"RESUMEN FINAL - RANDOM FOREST OPTIMIZADO\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"‚úÖ Modelo entrenado exitosamente\")\n",
    "print(f\"‚úÖ Hiperpar√°metros optimizados mediante b√∫squeda aleatoria\")\n",
    "print(f\"‚úÖ Validaci√≥n cruzada estratificada completada\")\n",
    "print(f\"‚úÖ Importancia de caracter√≠sticas analizada\")\n",
    "print(f\"‚úÖ Predicciones generadas para conjunto de test\")\n",
    "print(f\"‚úÖ Modelo y resultados guardados\")\n",
    "\n",
    "print(f\"\\nVENTAJAS DEL RANDOM FOREST:\")\n",
    "print(f\"- Robusto ante overfitting\")\n",
    "print(f\"- Maneja bien datos faltantes\")\n",
    "print(f\"- Proporciona importancia de caracter√≠sticas\")\n",
    "print(f\"- No requiere escalado de datos\")\n",
    "print(f\"- Paralelizable (r√°pido)\")\n",
    "print(f\"- Interpretable\")\n",
    "\n",
    "print(f\"\\nACCURACY FINAL: {accuracy_cv:.4f}\")\n",
    "print(f\"TIEMPO TOTAL: {elapsed/60:.2f} minutos\")\n",
    "print(f\"USO DE RAM: {final_memory:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
